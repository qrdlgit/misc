{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/paul/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "CONFIG = dotenv_values(\".env\")\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(CONFIG['HF'])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc48e00b8b04683a6bb80d6b50080d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58964fd68f884f4dac5839a25012e58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e12b74efc3a457ea0190f0560fe33dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MODEL = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "MODEL = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    #load_in_4bit=True,\n",
    "    #load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.tie_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is my API Call\n",
    "def generate_question(instruction):\n",
    "    output = pipeline(\n",
    "        instruction,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=1,\n",
    "        return_full_text=False\n",
    "    )\n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikis = []\n",
    "#for i in range(10):\n",
    "#    _df = pd.read_parquet(f\"./data/wiki_{i}_1k.parquet\")\n",
    "#    wikis.append(_df)\n",
    "#df = pd.concat(wikis).drop_duplicates(subset=['page_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/wiki_20k.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text):\n",
    "    question = re.findall(r'Question: (.*)\\n', text)\n",
    "    choice_a = re.findall(r'A[\\.|\\:|\\)] (.*)\\n', text)\n",
    "    choice_b = re.findall(r'B[\\.|\\:|\\)] (.*)\\n', text)\n",
    "    choice_c = re.findall(r'C[\\.|\\:|\\)] (.*)\\n', text)\n",
    "    choice_d = re.findall(r'D[\\.|\\:|\\)] (.*)\\n', text)\n",
    "    choice_e = re.findall(r'E[\\.|\\:|\\)] (.*)\\n', text)\n",
    "    answer = re.findall(r'Answer: ([A-E])', text)\n",
    "\n",
    "    assert len(question) > 0, \"Question is missing\"\n",
    "    assert len(choice_a) > 0, \"Choice A is missing\"\n",
    "    assert len(choice_b) > 0, \"Choice B is missing\"\n",
    "    assert len(choice_c) > 0, \"Choice C is missing\"\n",
    "    assert len(choice_d) > 0, \"Choice D is missing\"\n",
    "    assert len(choice_e) > 0, \"Choice E is missing\"\n",
    "    assert len(answer) > 0, \"Answer E is missing\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": question[0],\n",
    "        \"A\": choice_a[0],\n",
    "        \"B\": choice_b[0],\n",
    "        \"C\": choice_c[0],\n",
    "        \"D\": choice_d[0],\n",
    "        \"E\": choice_e[0],\n",
    "        \"answer\": answer[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ed9945dcfc471796eb589090806a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "model_type = MODEL.split('/')[1].lower().replace('-', '_')\n",
    "save_path = f\"./{model_type}_questions\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "for r in tqdm(df.itertuples(), total=len(df)):\n",
    "    try:\n",
    "        output = generate_question(r.instruction)\n",
    "        data = extract_data(output)\n",
    "        data['text'] = r.text\n",
    "        data['title'] = r.title\n",
    "        data['stem_label'] = r.stem_label\n",
    "        data['page_id'] = r.page_id\n",
    "        data['instruction'] = r.instruction\n",
    "        \n",
    "        data_id = str(uuid.uuid4())\n",
    "\n",
    "        data['id'] = data_id\n",
    "        data['model'] = model_type\n",
    "\n",
    "        generated_data.append(data)\n",
    "        \n",
    "        ## Write to save our precious work\n",
    "        with open(f\"{save_path}/{data_id}_{model_type}.json\", \"w\") as file:\n",
    "            file.write(json.dumps(data))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "generated_data = pd.DataFrame(generated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data.to_parquet(f\"{model_type}_questions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for r in generated_data.itertuples():\n",
    "#    print(r.text)\n",
    "#    print()\n",
    "#    print(f\"Prompt: {r.prompt}\")\n",
    "#    print(f\"A: {r.A}\")\n",
    "#    print(f\"B: {r.B}\")\n",
    "#    print(f\"C: {r.C}\")\n",
    "#    print(f\"D: {r.D}\")\n",
    "#    print(f\"E: {r.E}\")\n",
    "#    print(f\"Answer: {r.answer}\")\n",
    "#    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('llm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bafbb81b54046794fcd52f80959256aacfa44d034ba0922e7c94264489ae16c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
